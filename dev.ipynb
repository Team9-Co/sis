{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/team9/anaconda3/lib/python3.8/site-packages/ray/autoscaler/_private/cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import ray\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        base_model = VGG16(weights='imagenet')\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "    def extract(self, img):\n",
    "        \"\"\"\n",
    "        Extract a deep feature from an input image\n",
    "        Args:\n",
    "            img: from PIL.Image.open(path) or tensorflow.keras.preprocessing.image.load_img(path)\n",
    "\n",
    "        Returns:\n",
    "            feature (np.ndarray): deep feature with the shape=(4096, )\n",
    "        \"\"\"\n",
    "        img = img.resize((224, 224))  # VGG must take a 224x224 img as an input\n",
    "        img = img.convert('RGB')  # Make sure img is color\n",
    "        x = image.img_to_array(img)  # To np.array. Height x Width x Channel. dtype=float32\n",
    "        x = np.expand_dims(x, axis=0)  # (H, W, C)->(1, H, W, C), where the first elem is the number of img\n",
    "        x = preprocess_input(x)  # Subtracting avg values for each pixel\n",
    "        feature = self.model.predict(x)[0]  # (1, 4096) -> (4096, )\n",
    "        return feature / np.linalg.norm(feature)  # Normalize\n",
    "fe = FeatureExtractor()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 폴더 내 모든 파일\n",
    "img_paths = []\n",
    "# for path, dirs, files in os.walk(\"../../data/sa+p/train\"):\n",
    "for path, dirs, files in os.walk(\"../../data\"):\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1]\n",
    "        if ext == '.jpg':\n",
    "            img_paths.append(os.path.join(path, filename))\n",
    "img_paths = img_paths[:50000]   ### TEST 용 1000개 이미지         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-14 13:50:56,538\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "try:\n",
    "#     ray.init(num_cpus=num_cpus)\n",
    "    ray.init(num_cpus=num_cpus, num_gpus=2)\n",
    "except:\n",
    "    ray.shutdown()\n",
    "    ray.init(num_cpus=num_cpus, num_gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def getFeatures(img):\n",
    "    fe = FeatureExtractor()\n",
    "    flist = np.array([ fe.extract(Image.open(ip)) for ip in img ])\n",
    "    rst = [(img[i], v) for i, v in enumerate(flist)]\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_job(img_paths, func, num_cpus):\n",
    "    div = len(img_paths) // (num_cpus)\n",
    "    div += 1 if div%num_cpus > 0 else 0    \n",
    "    rst = [func.remote(img_paths[i*div:i*div+div]) for i in range(num_cpus)]\n",
    "    rst = ray.get(rst)\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:49.030529: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:49.007259: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:49.007259: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:49.033849: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:49.858932: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:49.889013: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:49.889044: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: team9-server\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:49.889050: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: team9-server\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:49.889146: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:49.889164: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:49.889168: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:49.889417: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:49.858983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:49.869437: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:49.869469: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: team9-server\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:49.869474: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: team9-server\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:49.869551: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:49.869570: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:49.869575: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:49.869847: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:50.029311: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:50.045278: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:50.045327: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: team9-server\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:50.045335: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: team9-server\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:50.045446: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:50.045471: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:50.045478: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:50.045860: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:50.029314: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:50.045555: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:50.045591: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: team9-server\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:50.051768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: team9-server\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:50.051917: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:50.051954: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:50.051961: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.84.0\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:50.052281: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:52.553879: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "\u001b[2m\u001b[36m(pid=177923)\u001b[0m 2021-07-10 23:56:52.571940: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3800000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:52.585493: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "\u001b[2m\u001b[36m(pid=177924)\u001b[0m 2021-07-10 23:56:52.585811: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3800000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:52.804966: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "\u001b[2m\u001b[36m(pid=177925)\u001b[0m 2021-07-10 23:56:52.805617: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3800000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:52.783690: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "\u001b[2m\u001b[36m(pid=177926)\u001b[0m 2021-07-10 23:56:52.784232: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3800000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 22.2 s, total: 2min 17s\n",
      "Wall time: 1h 41min 14s\n"
     ]
    }
   ],
   "source": [
    "%time rst = parallelize_job(img_paths, getFeatures, num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = []\n",
    "for i, v in enumerate(rst):\n",
    "    flist += v\n",
    "f=open('source_feature.p', 'wb')\n",
    "pickle.dump(flist, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "### div 단위로 분할해서 저장\n",
    "div = 600\n",
    "num = (len(img_paths) // div) \n",
    "num += 1 if len(img_paths) % div > 0 else 0\n",
    "\n",
    "f=open('source_feature.p', 'wb')\n",
    "pickle.dump(img_paths, f)\n",
    "\n",
    "for i in range(1, num+1):\n",
    "    flist = np.array([ fe.extract(Image.open(ip)) for ip in img_paths[(i-1)*div:i*div] ])\n",
    "    pickle.dump(flist, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 저장된 파일 읽어오기\n",
    "f=open('source_feature.p', 'rb')\n",
    "data = pickle.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 4096)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file = []\n",
    "source = []\n",
    "for p, d in data:\n",
    "    source_file.append(p.split('\\\\')[-1])\n",
    "    source.append(d) # reshape(64,64) 안해도 되나?    \n",
    "source = np.array(source)\n",
    "source.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.76 s ± 33.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "### 그룹 내 이미지 간 검색\n",
    "result = []\n",
    "bound = 0.5\n",
    "\n",
    "for i in range(source.shape[0]-1):\n",
    "    dists = np.linalg.norm(source[i+1:] - source[i], axis=1)  # L2 distances to features\n",
    "    dist_df = pd.DataFrame(dists, columns=['dist'])\n",
    "    dist_df = dist_df[dist_df.dist < bound].sort_values(by='dist')[:3]\n",
    "    result += [(dist_df.loc[idx].dist, source_file[i], source_file[idx+i+1]) for idx in dist_df.index]\n",
    "\n",
    "df = pd.DataFrame(result, columns = ['dist', 'query_img', 'source_img']).sort_values(by=['query_img', 'dist'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(999, 4096)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### 저장된 파일 읽어오기\n",
    "# f=open('source_feature.p', 'rb')\n",
    "# source_path = pickle.load(f)\n",
    "# source = pickle.load(f)\n",
    "# while True:\n",
    "#     try:\n",
    "#         source = np.concatenate((source, pickle.load(f)))\n",
    "#     except:\n",
    "#         break\n",
    "# print(len(source_path))\n",
    "# source.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 검색할 이미지와 저장된 이미지가 다른 경우\n",
    "p = r\"C:\\Users\\hyosun87.you\\Downloads\\4월실험1-자체 영수증 위조\\위조\"\n",
    "# p = r\"C:\\Users\\hyosun87.you\\Downloads\\Low Quality\"\n",
    "query_path = sorted(Path(p).glob(\"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.91 s ± 60.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "### 서로 다른 이미지 간 검색\n",
    "result = []\n",
    "bound = 0.5\n",
    "querys = np.array([ fe.extract(Image.open(qpath)) for qpath in query_path])\n",
    "for i, v in enumerate(querys):\n",
    "    dists = np.linalg.norm(source-v, axis=1)  # L2 distances to features\n",
    "    dist_df = pd.DataFrame(dists, columns=['dist'])\n",
    "    dist_df = dist_df[dist_df.dist < bound].sort_values(by='dist')[:3]\n",
    "    for idx in dist_df.index:\n",
    "        result.append((dist_df.loc[idx].dist, query_path[i].parts[-1], source_path[idx].parts[-1]))\n",
    "df = pd.DataFrame(result, columns = ['dist', 'query_img', 'source_img']).sort_values(by=['query_img', 'dist'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3 ms ± 118 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_path = 'model_index.idx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.1 s ± 176 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "index = nmslib.init(space='cosinesimil')\n",
    "index.addDataPointBatch(source)\n",
    "index_time_params = {'M': 15, 'indexThreadQty': 4, 'efConstruction': 100}\n",
    "index.createIndex(index_time_params)\n",
    "index.saveIndex(idx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_idx = nmslib.init(space='cosinesimil')\n",
    "m_idx.loadIndex(idx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n",
      "50000\n",
      "50000\n",
      "50000\n",
      "50000\n",
      "50000\n",
      "50000\n",
      "3.44 s ± 25.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# neighbors, distances = m_idx.knnQueryBatch(np.expand_dims(source[0], axis = 0), k = 3, num_threads = 4)[0] ### 1장일 경우\n",
    "s_rst = m_idx.knnQueryBatch(source, k = 3, num_threads = 10)\n",
    "print(len(s_rst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([   60,    90, 36036], dtype=int32),\n",
       "  array([1.1920929e-07, 1.1920929e-07, 1.1920929e-07], dtype=float32)),\n",
       " (array([   31,    61, 36079], dtype=int32),\n",
       "  array([0., 0., 0.], dtype=float32)),\n",
       " (array([   32,    92, 36038], dtype=int32),\n",
       "  array([5.9604645e-08, 5.9604645e-08, 5.9604645e-08], dtype=float32)),\n",
       " (array([ 3, 63, 93], dtype=int32), array([0., 0., 0.], dtype=float32)),\n",
       " (array([    4,    64, 36040], dtype=int32),\n",
       "  array([3.5762787e-07, 3.5762787e-07, 3.5762787e-07], dtype=float32))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_rst[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   60,     0, 36078], dtype=int32),\n",
       " array([1.1920929e-07, 1.1920929e-07, 1.1920929e-07], dtype=float32))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_rst[0] # ([검색된 이미지의 인덱스], [해당 이미지와의 거리]) 로 묶여서 출력 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.192093e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.192093e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36078.0</td>\n",
       "      <td>1.192093e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0             1\n",
       "0     60.0  1.192093e-07\n",
       "1      0.0  1.192093e-07\n",
       "2  36078.0  1.192093e-07"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4fde45515710cbe4f4cf44a8ddef1b298277709bd6c5462499553af68a98f2e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
